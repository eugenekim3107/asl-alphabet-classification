{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/eugenekim/PycharmProjects/asl-alphabet-classification/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_map = {\"A\":0, \"B\":1, \"C\":2, \"D\":3, \"del\":4, \"E\":5, \"F\":6,\n",
    "                \"G\":7,\"H\":8,\"I\":9,\"J\":10,\"K\":11,\"L\":12,\"M\":13,\"N\":14,\n",
    "                \"nothing\":15,\"O\":16,\"P\":17,\"Q\":18,\"R\":19,\"S\":20,\n",
    "                 \"space\":21,\"T\":22,\"U\":23,\"V\":24,\"W\":25,\"X\":26,\"Y\":27,\"Z\":28}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./raw_data\"\n",
    "test_path = \"asl_alphabet_test\"\n",
    "train_path = \"asl_alphabet_train\"\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "def get_asl_data(num_image, split=\"train\", normalized=False):\n",
    "    \n",
    "    #Desired parameters\n",
    "    inputs = \"empty\"\n",
    "    \n",
    "    if split == \"test\":\n",
    "        \n",
    "        outputs = None\n",
    "                \n",
    "        for letter in sorted(os.listdir(os.path.join(file_path,test_path))):\n",
    "\n",
    "            #Check if image ends with \".jpg\"\n",
    "            if not letter.endswith(\".jpg\"):\n",
    "                continue\n",
    "\n",
    "            #Read image\n",
    "            read_image = cv2.imread(os.path.join(file_path,test_path,letter))\n",
    "\n",
    "            #Convert to RGB\n",
    "            temp_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "            #Convert the image to tensor\n",
    "            image_tensor = transform(temp_image)\n",
    "                \n",
    "            if inputs == \"empty\":\n",
    "                inputs = image_tensor\n",
    "                    \n",
    "            else:\n",
    "                inputs = torch.vstack((inputs,image_tensor))\n",
    "        \n",
    "        return inputs, outputs\n",
    "    \n",
    "    if split == \"train\":\n",
    "            \n",
    "        #Desired labels\n",
    "        outputs = \"empty\"\n",
    "            \n",
    "        for letter in sorted(os.listdir(os.path.join(file_path,train_path))):\n",
    "            \n",
    "            count = 0\n",
    "                \n",
    "            if letter == \".DS_Store\":\n",
    "                continue\n",
    "                    \n",
    "            map_letter = numerical_map[letter]\n",
    "                \n",
    "            for image in sorted(os.listdir(os.path.join(file_path,train_path,letter))):\n",
    "                \n",
    "                if count == num_image:\n",
    "                    break\n",
    "                \n",
    "                if not image.endswith(\".jpg\"):\n",
    "                    continue\n",
    "\n",
    "                read_image = cv2.imread(os.path.join(file_path,train_path,letter,image))\n",
    "\n",
    "                #Convert to RGB\n",
    "                temp_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                #Convert the image to tensor\n",
    "                image_tensor = transform(temp_image)\n",
    "                \n",
    "                if outputs == \"empty\":\n",
    "                    outputs = torch.tensor([map_letter])\n",
    "                    \n",
    "                else:\n",
    "                    outputs = torch.vstack((outputs,torch.tensor([map_letter])))\n",
    "                \n",
    "                if inputs == \"empty\":\n",
    "                    inputs = image_tensor\n",
    "                    count += 1\n",
    "                    \n",
    "                else:\n",
    "                    inputs = torch.vstack((inputs,image_tensor))\n",
    "                    count += 1\n",
    "            \n",
    "        return inputs, outputs\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, split, num_image, transform=None):\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.inputs, self.outputs = get_asl_data(num_image, split = split, normalized=False)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ASLDataset(split = \"train\", num_image=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, \"ASLDataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
