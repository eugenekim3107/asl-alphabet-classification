{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/eugenekim/PycharmProjects/asl-alphabet-classification/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_map = {\"A\":0, \"B\":1, \"C\":2, \"D\":3, \"del\":4, \"E\":5, \"F\":6,\n",
    "                \"G\":7,\"H\":8,\"I\":9,\"J\":10,\"K\":11,\"L\":12,\"M\":13,\"N\":14,\n",
    "                \"nothing\":15,\"O\":16,\"P\":17,\"Q\":18,\"R\":19,\"S\":20,\n",
    "                 \"space\":21,\"T\":22,\"U\":23,\"V\":24,\"W\":25,\"X\":26,\"Y\":27,\"Z\":28}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./raw_data\"\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "def get_asl_data(split=\"train\", normalized=False):\n",
    "    \n",
    "    #Desired parameters\n",
    "    inputs = \"empty\"\n",
    "    \n",
    "    #Loop through data file\n",
    "    for data in sorted(os.listdir(file_path)):\n",
    "        if data == \"asl_alphabet_test\":\n",
    "                \n",
    "            for letter in sorted(os.listdir(os.path.join(file_path,data))):\n",
    "\n",
    "                #Check if image ends with \".jpg\"\n",
    "                if not letter.endswith(\".jpg\"):\n",
    "                    continue\n",
    "\n",
    "                #Read image\n",
    "                read_image = cv2.imread(os.path.join(file_path,data,letter))\n",
    "\n",
    "                #Convert to RGB\n",
    "                temp_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                #Convert the image to tensor\n",
    "                image_tensor = transform(temp_image)\n",
    "                \n",
    "                if inputs == \"empty\":\n",
    "                    inputs = image_tensor\n",
    "                    \n",
    "                else:\n",
    "                    inputs = torch.vstack((inputs,image_tensor))\n",
    "    \n",
    "        if data == \"asl_alphabet_train\":\n",
    "            \n",
    "            #Desired labels\n",
    "            outputs = \"empty\"\n",
    "            \n",
    "            for letter in sorted(os.listdir(os.path.join(file_path,data))):\n",
    "                \n",
    "                if letter == \".DS_Store\":\n",
    "                    continue\n",
    "                    \n",
    "                map_letter = numerical_map[letter]\n",
    "                    \n",
    "                if outputs == \"empty\":\n",
    "                    outputs = torch.tensor([map_letter])\n",
    "                    \n",
    "                else:\n",
    "                    outputs = torch.vstack((outputs,torch.tensor([map_letter])))\n",
    "                \n",
    "                for image in sorted(os.listdir(os.path.join(file_path,data,letter))):\n",
    "                    if not image.endswith(\".jpg\"):\n",
    "                        continue\n",
    "\n",
    "                    read_image = cv2.imread(os.path.join(file_path,data,letter,image))\n",
    "\n",
    "                    #Convert to RGB\n",
    "                    temp_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    #Convert the image to tensor\n",
    "                    image_tensor = transform(temp_image)\n",
    "                    \n",
    "                    if inputs == \"empty\":\n",
    "                        inputs = image_tensor\n",
    "                    else:\n",
    "                        inputs = torch.vstack((inputs,image_tensor))\n",
    "  \n",
    "                if outputs == \"empty\":\n",
    "                    outputs = letter\n",
    "                    \n",
    "                else:\n",
    "                    outputs = torch.vstack((outputs,letter))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1   2 252]\n",
      "  [  1   0 248]\n",
      "  [ 10   0 249]\n",
      "  ...\n",
      "  [  4   0 248]\n",
      "  [  3   4 252]\n",
      "  [  0   0 246]]\n",
      "\n",
      " [[  1   1 249]\n",
      "  [  3   1 234]\n",
      "  [ 15   6 209]\n",
      "  ...\n",
      "  [ 17   6 198]\n",
      "  [  4   2 210]\n",
      "  [  6  11 227]]\n",
      "\n",
      " [[  0   0 241]\n",
      "  [ 10   8 206]\n",
      "  [ 39  32 144]\n",
      "  ...\n",
      "  [189 173 244]\n",
      "  [174 165 255]\n",
      "  [ 11   7 164]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  5   3 254]\n",
      "  [  3   3 195]\n",
      "  [129 135 213]\n",
      "  ...\n",
      "  [144 129 158]\n",
      "  [135 125 224]\n",
      "  [ 17   9 144]]\n",
      "\n",
      " [[  0   0 251]\n",
      "  [  4   8 219]\n",
      "  [120 124 255]\n",
      "  ...\n",
      "  [136 126 225]\n",
      "  [118 114 253]\n",
      "  [ 15  13 172]]\n",
      "\n",
      " [[  0   1 251]\n",
      "  [  2   6 227]\n",
      "  [  7  10 173]\n",
      "  ...\n",
      "  [ 19  11 146]\n",
      "  [ 17  13 172]\n",
      "  [  7   7 179]]]\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./raw_data\"\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    #Loop through data file\n",
    "for data in sorted(os.listdir(file_path)):\n",
    "    if data == \"asl_alphabet_test\":\n",
    "        for letter in sorted(os.listdir(os.path.join(file_path,data))):\n",
    "\n",
    "                    #Check if image ends with \".jpg\"\n",
    "            if not letter.endswith(\".jpg\"):\n",
    "                continue\n",
    "\n",
    "                    #Read image\n",
    "            read_image = cv2.imread(os.path.join(file_path,data,letter))\n",
    "\n",
    "                    #Convert to RGB\n",
    "            temp_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    #Convert the image to tensor\n",
    "            image_tensor = transform(temp_image)\n",
    "\n",
    "    #                 inputs = np.append(inputs, temp_image)\n",
    "\n",
    "    if data == \"asl_alphabet_train\":\n",
    "\n",
    "        for letter in sorted(os.listdir(os.path.join(file_path,data))):\n",
    "\n",
    "            if letter == \".DS_Store\":\n",
    "                continue\n",
    "            for image in sorted(os.listdir(os.path.join(file_path,data,letter))):\n",
    "                if not image.endswith(\".jpg\"):\n",
    "                    continue\n",
    "\n",
    "                read_image = cv2.imread(os.path.join(file_path,data,letter,image))\n",
    "\n",
    "                        #Convert to RGB\n",
    "                temp_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "                print(temp_image)\n",
    "                        #Convert the image to tensor\n",
    "                image_tensor = transform(temp_image)\n",
    "\n",
    "                print(type(image_tensor))\n",
    "                break\n",
    "            break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-678bd1130158>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-678bd1130158>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class ASLDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.csv_file = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4982, -1.1242,  1.1630],\n",
       "         [-0.2272,  1.3963, -0.3712]],\n",
       "\n",
       "        [[-0.2285,  0.5456, -0.3234],\n",
       "         [ 0.5971,  0.1079,  1.4651]],\n",
       "\n",
       "        [[-0.3058,  1.8598,  0.3218],\n",
       "         [-0.9250,  0.1210,  0.5844]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack((x,x),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4982,  0.4982],\n",
       "          [-1.1242, -1.1242],\n",
       "          [ 1.1630,  1.1630]],\n",
       "\n",
       "         [[-0.2272, -0.2272],\n",
       "          [ 1.3963,  1.3963],\n",
       "          [-0.3712, -0.3712]]],\n",
       "\n",
       "\n",
       "        [[[-0.2285, -0.2285],\n",
       "          [ 0.5456,  0.5456],\n",
       "          [-0.3234, -0.3234]],\n",
       "\n",
       "         [[ 0.5971,  0.5971],\n",
       "          [ 0.1079,  0.1079],\n",
       "          [ 1.4651,  1.4651]]],\n",
       "\n",
       "\n",
       "        [[[-0.3058, -0.3058],\n",
       "          [ 1.8598,  1.8598],\n",
       "          [ 0.3218,  0.3218]],\n",
       "\n",
       "         [[-0.9250, -0.9250],\n",
       "          [ 0.1210,  0.1210],\n",
       "          [ 0.5844,  0.5844]]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
